const svmjs = require('svm'); // https://github.com/karpathy/svmjs

export default class SVMTrainer {
  constructor(converterFn) {
    this.converterFn = converterFn || (input => input); // Default to returning example as-is
    this.svm = new svmjs.SVM();
    this.svmParams = {}; // See https://github.com/karpathy/svmjs/blob/b75b71289dd81fc909a5b3fb8b1caf20fbe45121/lib/svm.js#L27
    this.labeledTrainingData = [];
  }

  /**
   * @param {Array<number>} data
   * @param {number} classId
   */
  addTrainingExample(example, classId) {
    // This SVM library only accepts 1 and -1 as labels; convert from our 0/1 labeling scheme
    const convertedExample = this.converterFn(example);
    const svmLabel = classId === 1 ? 1 : -1;
    this.labeledTrainingData.push({example: convertedExample, label: svmLabel});
  }

  train() {
    if (this.labeledTrainingData.length > 1) {
      const trainingData = this.labeledTrainingData.map(ld => ld.example);
      const trainingLabels = this.labeledTrainingData.map(ld => ld.label);
      this.svm.train(trainingData, trainingLabels, this.svmParams);
    }
  }

  /**
   * @param {Array<number>} data
   * @returns {Promise<{confidencesByClassId: [], predictedClassId: null}>}
   */
  async predict(example) {
    let result = {
      predictedClassId: null,
      confidencesByClassId: []
    };

    if (this.labeledTrainingData.length === 0) {
      return result;
    }

    const inputVector = this.converterFn(example);
    let res;
    /*
     * To keep SVM behaviour consistent with KNN, if there was only one
     * data point given, force all predictions to have that label.
     */
    if (this.labeledTrainingData.length === 1) {
      res = [this.labeledTrainingData[0].label];
    } else {
      res = this.svm.predict([inputVector]);
    }

    // This SVM library uses 1 and -1 as labels; convert back to our 0/1 labeling scheme
    result.predictedClassId = res[0] === 1 ? 1 : 0;
    const confidences = {};
    confidences[result.predictedClassId] = Math.abs(this.svm.marginOne(inputVector));
    result.confidencesByClassId = confidences;
    return result;
  }

  /**
   * @param {Array<FieldInfo>} FieldInfos object which describes each field of the data the model was trained on.
   *  Currently this is generated by the Fish object, so each Fish object will have an identical fieldInfos field.
   * @returns {List<{fieldInfo: FieldInfo, absWeight: number}>} The absolute value of the weight of the trained model for each field.
   *  All absWeight values are real numbers >= 0.
   */
  detailedExplanation(fieldInfos) {
    const fieldsAndValues = [];
    for (var i = 0; i < this.svm.w.length; i++) {
      fieldsAndValues.push({
        fieldInfo: fieldInfos[i],
        absWeight: Math.abs(this.svm.w[i]),
        sign: this.svm.w[i] >= 0 ? 1 : -1
      });
    }
    fieldsAndValues.sort((a, b) => b.absWeight - a.absWeight);
    return fieldsAndValues;
  }

  /**
   * @param {Array<FieldInfo>} FieldInfos object which describes each field of the data the model was trained on.
   *  Currently this is generated by the Fish object, so each Fish object will have an identical fieldInfos field.
   * @returns {List<{partType: string, importance: number}>} A summary of the importance of each part type (mouth, eyes, etc.) to the model.
   *  All importance values are real numbers >= 0.
   */
  summarize(fieldInfos) {
    const weightData = this.detailedExplanation(fieldInfos);
    /* separate the "id" fields, which are the fields generated by one-hot encoding the variation id for each part, with the "attribute"
     * fields, which are the hand-crafted metadata values such as number of teeth, since we need to treat the two differently in the summary. */
    const idFields = weightData.filter(d => d.fieldInfo.fieldType === 'id');
    const attributeFields = weightData.filter(d => d.fieldInfo.fieldType === 'attribute');

    /* Aggregate all the fields generated by one-hot encoding back into one per part, since we don't want the number of variations for a part
     * to influence its weight.
     * Aggregate by picking the maximum value per part, since only one of these fields can be "used" for a particular input.
     * This is a heuristic from experimenting and seeing what "looks right", may not be ideal in all cases. - @winter */
    for (const fieldWithWeight of idFields) {
      const partType = fieldWithWeight.fieldInfo.partType;
      if (!idFieldsSummary.hasOwnProperty(partType) || fieldWithWeight.absWeight > idFieldsSummary[partType]) {
        idFieldsSummary[partType] = fieldWithWeight.absWeight;
      }
    }

    // Sum all of the weights per part from the attribute fields and the idFieldsSummary. Result is a map of partType: totalAbsWeight.
    const rawSummary = {};
    for (const fieldWithWeight of attributeFields) {
      const partType = fieldWithWeight.fieldInfo.partType;
      if (!rawSummary.hasOwnProperty(partType)) {
        rawSummary[partType] = 0;
      }
      rawSummary[partType] += fieldWithWeight.absWeight;
    }
    for (const [partType, weight] of Object.entries(idFieldsSummary)) {
      if (!rawSummary.hasOwnProperty(partType)) {
        rawSummary[partType] = 0;
      }
      rawSummary[partType] += weight;
    }

    // Sort entries and convert to return format.
    const sortedSummary = Object.entries(rawSummary)
      .map(e => {return {partType: e[0], importance: e[1]}})
      .sort((a, b) => b.importance - a.importance);

    // Normalize importance such that all of the importance values add up to 1. This lets us use results as percentages if we want.
    var denominator = 0;
    for (const partWithImportance of sortedSummary) {
      denominator += partWithImportance.importance;
    }
    const sortedAndNormalizedSummary = sortedSummary.map(p => {return {partType: p.partType, importance: p.importance / denominator}});
    return sortedAndNormalizedSummary;
  }

  /**
   * @param {Fish} Fish object to explain the model's prediction for.
   *  Currently this is generated by the Fish object, so each Fish object will have an identical fieldInfos field.
   * @returns {List<{partType: string, impact: number}>} A summary of the impact of each part type (mouth, eyes, etc.) on the prediction
   *  result for this specific fish. Impact can be a positive or negative real number - a larger absolute value means more impact. A negative
   *  impact means it contributed to a "Like" and a positive impact means it contributed to a "Dislike". 
   */
  explainFish(fish) {
    /* Translate the fish's data to "remove" the bias term from the model. The relative weights for each field don't always correspond to
     * contribution to prediction with a high bias value, which will happen for skewed data sets. */
    const translatedVector = this.removeBiasTranslate(fish.knnData);

    const impactByPart = {};
    for (var i = 0; i < this.svm.w.length; i++) {
      const partType = fish.fieldInfos[i].partType;
      if (!impactByPart.hasOwnProperty(partType)) {
        impactByPart[partType] = 0;
      }

      impactByPart[partType] += this.svm.w[i] * translatedVector[i];
    }

    const sortedImpact = Object.entries(impactByPart)
      .map(e => {return {partType: e[0], impact: e[1]}})
      .sort((a, b) => Math.abs(b.impact) - Math.abs(a.impact));

    return sortedImpact;
  }

  /* Translates the given input vector such that the model would give the same prediction without its bias term.
   * Used so we can explain the importance of each feature without the concepot of bias.
   */
  removeBiasTranslate(vector) {
    // For bias term b, model weights a = [a1, a2, ... ad] and input vector [x1, x2, ... xd], the translation vector we add to
    // the original vector is (b / ||a||^2) * a. The intuition is that we are translating the separating hyperplane along its perpendicular
    // vector until it intersects with the origin, and applying the same translation to the input vector.
    const translationConstant = this.svm.b / magnitude_squared(this.svm.w); 
    const translationVector = this.svm.w.map(x => x * translationConstant);    

    const result = [];
    for (var i = 0; i < vector.length; i++) {
      result[i] = vector[i] + translationVector[i];
    }
    return result;
  }

  // Only needed for testing / validation of removeBiasTranslate
  translatedPredict(vector) {
    const translatedVector = this.removeBiasTranslate(vector);
    var margin = 0;
    for (var i = 0; i < translatedVector.length; i++) {
      margin += this.svm.w[i] * translatedVector[i];
    }
    return margin > 0 ? 1 : -1;
  }
}

// helper function - returns ||v|||^2 for input vector v
const magnitude_squared = (vector) => {
  var sum = 0;
  for (const x of vector) {
    sum += Math.pow(x, 2);
  }
  return sum;
};
